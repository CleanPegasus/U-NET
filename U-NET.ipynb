{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 128\n",
    "img_height = 128\n",
    "img_channels = 3\n",
    "\n",
    "train_path = 'U_NET/train/'\n",
    "test_path = 'U_NET/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(train_path))[1]\n",
    "test_ids = next(os.walk(test_path))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), 128, 128, 3), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), 128, 128, 1), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [07:30<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    \n",
    "    path = train_path + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    img = resize(img, (128, 128), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((128, 128, 1), dtype=np.bool)\n",
    "    \n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        \n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (128, 128), mode='constant', preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "        Y_train[n] = mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:02<00:00, 23.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.zeros((len(test_ids), 128, 128, 3), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = test_path + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:3]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (128, 128), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = label(y_true_in > 0.5)\n",
    "    y_pred = label(y_pred_in > 0.5)\n",
    "    \n",
    "    true_objects = len(np.unique(labels))\n",
    "    pred_objects = len(np.unique(y_pred))\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    iou = intersection / union\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1\n",
    "        false_positives = np.sum(matches, axis=0) == 0\n",
    "        false_negatives = np.sum(matches, axis=1) == 0\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.array(np.mean(metric), dtype=np.float32)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    metric_value = tf.compat.v1.py_func(iou_metric_batch, [label, pred], tf.float32)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    inputs = Input((128, 128, 3))\n",
    "    \n",
    "    x = inputs\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (x)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics = [my_iou_metric])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1228 21:34:48.940831 139913910433600 deprecation.py:323] From <ipython-input-24-a3fe61a0a9aa>:57: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.4068 - my_iou_metric: 0.0441\n",
      "Epoch 00001: val_loss improved from inf to 0.20122, saving model to model.h5\n",
      "603/603 [==============================] - 70s 116ms/sample - loss: 0.4030 - my_iou_metric: 0.0488 - val_loss: 0.2012 - val_my_iou_metric: 0.2132\n",
      "Epoch 2/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.2216 - my_iou_metric: 0.2388\n",
      "Epoch 00002: val_loss improved from 0.20122 to 0.16762, saving model to model.h5\n",
      "603/603 [==============================] - 70s 116ms/sample - loss: 0.2207 - my_iou_metric: 0.2395 - val_loss: 0.1676 - val_my_iou_metric: 0.3291\n",
      "Epoch 3/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1493 - my_iou_metric: 0.3482\n",
      "Epoch 00003: val_loss improved from 0.16762 to 0.14643, saving model to model.h5\n",
      "603/603 [==============================] - 71s 117ms/sample - loss: 0.1489 - my_iou_metric: 0.3503 - val_loss: 0.1464 - val_my_iou_metric: 0.4119\n",
      "Epoch 4/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1339 - my_iou_metric: 0.3900\n",
      "Epoch 00004: val_loss improved from 0.14643 to 0.14094, saving model to model.h5\n",
      "603/603 [==============================] - 70s 116ms/sample - loss: 0.1350 - my_iou_metric: 0.3858 - val_loss: 0.1409 - val_my_iou_metric: 0.3954\n",
      "Epoch 5/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1205 - my_iou_metric: 0.4345\n",
      "Epoch 00005: val_loss improved from 0.14094 to 0.11975, saving model to model.h5\n",
      "603/603 [==============================] - 70s 117ms/sample - loss: 0.1209 - my_iou_metric: 0.4335 - val_loss: 0.1198 - val_my_iou_metric: 0.4450\n",
      "Epoch 6/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1163 - my_iou_metric: 0.4522\n",
      "Epoch 00006: val_loss improved from 0.11975 to 0.11283, saving model to model.h5\n",
      "603/603 [==============================] - 70s 117ms/sample - loss: 0.1176 - my_iou_metric: 0.4513 - val_loss: 0.1128 - val_my_iou_metric: 0.4911\n",
      "Epoch 7/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1071 - my_iou_metric: 0.4612\n",
      "Epoch 00007: val_loss improved from 0.11283 to 0.10601, saving model to model.h5\n",
      "603/603 [==============================] - 70s 116ms/sample - loss: 0.1064 - my_iou_metric: 0.4659 - val_loss: 0.1060 - val_my_iou_metric: 0.5041\n",
      "Epoch 8/10\n",
      "592/603 [============================>.] - ETA: 1s - loss: 0.1001 - my_iou_metric: 0.4838\n",
      "Epoch 00008: val_loss did not improve from 0.10601\n",
      "603/603 [==============================] - 70s 117ms/sample - loss: 0.1001 - my_iou_metric: 0.4821 - val_loss: 0.1601 - val_my_iou_metric: 0.4654\n",
      "Epoch 9/10\n",
      "448/603 [=====================>........] - ETA: 17s - loss: 0.0993 - my_iou_metric: 0.4806"
     ]
    }
   ],
   "source": [
    "model_path = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path,\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1,\n",
    "                    batch_size=16, epochs=10, \n",
    "                    callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
